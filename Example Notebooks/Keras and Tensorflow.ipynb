{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf\n",
    "\n",
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "\n",
    "    layers.Dense(10)])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(32,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))\n",
    "\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "predictions = layers.Dense(10)(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Dense(units=64, activation=('relu'), \n",
    "    use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', \n",
    "    kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.01),\n",
    "    bias_regularizer=l1_l2(l1=0.01, l2=0.01), kernel_constraint=max_norm(2.), bias_constraint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D(filters=32, kernel_size=5, strides=(1, 1), padding='valid', data_format='channels_last', dilation_rate=(1, 1), \n",
    "    activation=\"relu\", \n",
    "    use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, \n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format='channels_last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.LSTM(units=64, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "                  kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', \n",
    "                  unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, \n",
    "                  activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, \n",
    "                  dropout=0.0, recurrent_dropout=0.0, implementation=2, return_sequences=False, return_state=False, \n",
    "                  go_backwards=False, stateful=False, unroll=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', \n",
    "                                gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', \n",
    "                                beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))\n",
    "\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "output1 = layers.Dense(64, activation='relu')(x)\n",
    "output2 = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "added = keras.layers.Add()([output1, output2])\n",
    "subtracted = keras.layers.Subtract()([output1, output2])\n",
    "\n",
    "multiply = keras.layers.Multiply()([output1, output2])\n",
    "concatenate = keras.layers.Concatenate()([output1, output2])\n",
    "average = keras.layers.Average()([output1, output2])\n",
    "\n",
    "predictions = layers.Dense(10)(added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activations = sigmoid, tanh, relu, leaky relu, prelu, elu, threshold relu, selu, softmax, linear, softplus, softsign, hard sigmoid, exponential.\n",
    "\n",
    "initializers = zeros, ones, constant, random normal, random uniform, truncated normal, variance scaling, orthogonal, identity, lecun uniform, glorot normal, glorot uniform, he normal, lecun normal, he uniform. \n",
    "\n",
    "losses = mean squared error, mean absolute error, mean absolute percentage error, mean squared logarithmic error, squared hinge, hinge, categorical hinge, logcash, huber loss, categorical crossentropy, sparse categorical crossentropy, binary crossentropy, kullback leibler divergence, poisson, cosine proximity, is categorical crossentropy.\n",
    "\n",
    "optimizers = SGD, rms prop, adagrad, adadelta, adamax, adam, nadam, amsgrad. \n",
    "\n",
    "metrics = accuracy, binary accuracy, categorical accuracy, sparse categorical accuracy, top k categorical accuracy, sparse top k categorical accuracy, cosine proximity, clone metric. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
